#!/bin/bash -l
#
# Script to run shark under a queueing system
#
# ICRAR - International Centre for Radio Astronomy Research
# (c) UWA - The University of Western Australia, 2018
# Copyright by UWA (in the framework of the ICRAR)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#

info() {
	echo "shark-run: $1"
}

error() {
	echo "shark-run: ERROR: $1" 1>&2
}

warning() {
	echo "shark-run: WARNING: $1" 1>&2
}

repeat() {
	_all_vals=""
	for x in `eval echo {1..$2}`
	do
		_all_vals="$_all_vals $1"
	done
	echo "${_all_vals## }"
}

# Turns SLURM quantities specifications to lists of individual values
# For example:
#
# "48(x3),24" --> "48 48 48 24"
_slurm_quantity_as_list() {
	_comma_separated_vals="${1//,/ }"
	_all_vals=""
	for val in $_comma_separated_vals
	do
		if [[ "$val" =~ ^([0-9]+)\(x([0-9]+)\) ]]
		then
			_amount=${BASH_REMATCH[1]}
			_rep=${BASH_REMATCH[2]^*}
			_all_vals="$_all_vals `repeat $_amount $_rep`"
		else
			_all_vals="$_all_vals $val"
		fi
	done

	echo "${_all_vals## }"
}

print_usage() {
	echo
	echo "$0: Runs shark under a queueing environment"
	echo
	echo "Usage: $0 [-h] [-?] [-v verbosity-level] [-m modules] [-S shark_binary] -V subvolumes"
	echo "       config_file"
	echo
	echo " -h, -?: Show this help"
	echo " -v verbosity-level: shark verbosity"
	echo " -m modules: colon-separted list of modules to load before running shark"
	echo " -S: The shark binary to run. Defaults to standard PATH lookup"
	echo " -V: Space-separated list of subvolumes to process. Can contain ranges like 1-10"
	echo " config_file: The reference configuration file to use for this shark execution"
}

# Check we are under the influence of a queueing system
if [ -z "${SLURM_JOB_ID}" ]
then
	warning ""
	warning "THIS IS NOT MEANT TO HAPPEN"
	warning ""
	warning "You seem to be manually running this script, but this script is designed to be run"
	warning "under a queueing system (PBS/Torque or SLURM) in an HPC facility."
	warning ""
	warning "If you are indeed in an HPC center and trying to run shark, you most probably want"
	warning "to run the shark-submit script (which in turn will invoke us internally)."
	warning ""
	warning "Now, if you are really sure of what you are doing, you have nothing to fear..."
	warning ""
fi

# The submit script should have told us where it lives,
# which is needed later on to deduce where the standard
# python plotting scripts live
if [ -z "$SHARK_HPC_DIR" ]
then
	warning "SHARK_HPC_DIR environment variable not set"
	warning
	warning "This variable should have been set by the shark-submit script automatically"
	warning "to properly support running the python standard plot scripts. If for some reason you"
	warning "are running this script manually you will need to export this variable yourself"
	warning "and point it to the hpc/ directory within the shark git repository."
	warning
	warning "Given that this is not the case, this variable will now be defaulted"
	warning "to this script's parent directory, which might or might not be what you need."

	# See shark-submit fot details on this
	this=$0
	if [ -h $0 ]
	then
		this=$(readlink -f $0)
	fi
	p="`dirname $this`"
	SHARK_HPC_DIR="`cd $p; echo $PWD; cd $OLDPWD`"
fi

# Print queueing information for this job
if [ ! -z "$SLURM_JOB_ID" ]
then
	info ""
	info "Dumping SLURM information for this job submission:"
	info ""
	info "Variable                 Description                           Value"
	info "--------------------------------------------------------------------------------"
	info "SLURM_CLUSTER_NAME       The cluster we are running shark on   $SLURM_CLUSTER_NAME"
	info "SLURM_SUBMIT_DIR         Directory the job was submitted from  $SLURM_SUBMIT_DIR"
	info "SLURM_JOB_PARTITION      The partition we are running shark on $SLURM_JOB_PARTITION"
	info "SLURM_JOB_NAME           Name of the job                       $SLURM_JOB_NAME"
	info "SLURM_JOB_ID             This job's unique identifier job      $SLURM_JOB_ID"
	info "SLURM_JOB_NODELIST       Name of nodes assigned                $SLURM_JOB_NODELIST"
	info "SLURM_JOB_NUM_NODES      Number of nodes allocated             $SLURM_JOB_NUM_NODES"
	info "SLURM_JOB_CPUS_PER_NODE  #CPUs per node available              $SLURM_JOB_CPUS_PER_NODE"
	info "SLURM_NTASKS             #Tasks allocated                      $SLURM_NTASKS"
	info "SLURM_TASKS_PER_NODE     #Tasks to run per node                $SLURM_TASKS_PER_NODE"
	info "SLURM_MEM_PER_CPU        #Allocated memory per CPU             $SLURM_MEM_PER_CPU"
	info "SLURM_MEM_PER_NODE       #Allocated memory per node            $SLURM_MEM_PER_NODE"
	info "SLURM_CPUS_PER_TASK      #CPUs to be used by each task         $SLURM_CPUS_PER_TASK"
	info ""
fi

# Default option values
# These are global variables, so we don't need to pass them around all the time
verbose=
module_names=
shark_verbosity=3
shark_binary=
shark_subvolumes=
shark_options=()
shark_plot=
shark_python_exec=python
shark_obsdata_dir=

# Parse command line options
while getopts "h?m:v:S:V:o:pP:D:" opt
do
	case "$opt" in
		[h?])
			print_usage
			exit 0
			;;
		v)
			shark_verbosity="$OPTARG"
			;;
		m)
			module_names="$OPTARG"
			;;
		S)
			shark_binary="$OPTARG"
			;;
		V)
			shark_subvolumes="$OPTARG"
			;;
		o)
			shark_options+=("$OPTARG")
			;;
		p)
			shark_plot=yes
			;;
		P)
			shark_python_exec="${OPTARG}"
			;;
		D)
			shark_obsdata_dir="$OPTARG"
			;;
		*)
			print_usage 1>&2
			exit 1
			;;
	esac
done

# Make sure we have a list of subvolumes to process
if [ -z "$shark_subvolumes" ]
then
	error "Missing -V option with subvolumes list"
	print_usage 1>&2
	exit 1
fi
shark_subvolumes=($shark_subvolumes)

# Positional argument is the configuration file name
if [ $(($# - $OPTIND)) -lt 0 ]
then
	print_usage 1>&2
	exit 1
fi

config_file=${@:$OPTIND:1}

# Which shark binary should be used
shark_binary=${shark_binary:-shark}

# Make sure the configuration file exists before submitting
if [ ! -f ${config_file} ]
then
	error "File ${config_file} is not an existing (or accessible) file"
	exit 1
fi

# List and load modules
if [ ! -z "$module_names" ]
then
	module_names="${module_names//:/ }"
	info "Loading modules specified by user: $module_names"
	for m in $module_names
	do
		info "Loading module $m"
		module load "$m" || (error "Failed to load module $m" && exit 1)
	done
fi

cpus_per_node=(`_slurm_quantity_as_list $SLURM_JOB_CPUS_PER_NODE`)
tasks_per_node=(`_slurm_quantity_as_list $SLURM_TASKS_PER_NODE`)
info "CPUs per node: ${cpus_per_node[*]}"
info "Tasks per node: ${tasks_per_node[*]}"

mem_per_task=${SLURM_MEM_PER_CPU:-}
if [ -z "$mem_per_task" ]
then
	if [ -z "$SLURM_MEM_PER_NODE" ]
	then
		error "Neither SLURM_MEM_PER_CPU nor SLURM_MEM_PER_NODE could be found, cannot calculate memory per shark instance"
		exit 1
	fi

	mem_per_node=(`_slurm_quantity_as_list $SLURM_MEM_PER_NODE`)
	if [ ${#mem_per_node[*]} = 1 ]
	then
		mem_per_node=(`repeat $mem_per_node $SLURM_JOB_NUM_NODES`)
	fi
	info "Memory per node: ${mem_per_node[*]}"

	mem_per_task=""
	for i in `eval echo {1..${#mem_per_node[*]}}`
	do
		let "i = i - 1"
		t=${tasks_per_node[i]}
		m=${mem_per_node[i]}
		mem_per_task="$mem_per_task `repeat $(($m / $t)) $t`"
	done
	mem_per_task=($mem_per_task)
else
	mem_per_task=(`repeat $mem_per_task ${#shark_subvolumes[*]}`)
fi

cpus_per_task=""
for i in `eval echo {1..${#cpus_per_node[*]}}`
do
	let "i = i - 1"
	c=${cpus_per_node[i]}
	t=${tasks_per_node[i]}
	div=$(( $c / $t ))
	rem=$(( $c % $t ))

	# Distribute CPUs within a node in round-robin fashion
	if [ $rem = 0 ]
	then
		cpus_per_task="$cpus_per_task `repeat $div $t`"
	else
		cpus_per_task="$cpus_per_task `repeat $div $(($t - $rem))` `repeat $(( $div + 1 )) $rem`"
	fi
done
cpus_per_task=($cpus_per_task)
info "CPUs per task: ${cpus_per_task[*]}"
info "Memory per task: ${mem_per_task[*]}"

# Calculate the command to run
# If possible, we time each execution (but it's not really necessary)
cmd="srun --exclusive -n 1 -N 1"
post_cmd=""
if [ -n "$(command -v time 2> /dev/null)" -a "`type -t time`" = "file" ]
then
	post_cmd="time"
fi
post_cmd="$post_cmd $shark_binary "
for o in ${shark_options[*]}
do
	post_cmd="$post_cmd -o $o"
done
post_cmd="$post_cmd -v $shark_verbosity $config_file"

info "Processing ${#shark_subvolumes[*]} subvolume(s): ${shark_subvolumes[*]}"
info ""
info "================================================================================"
info "Starting shark via srun with command-line:"
info "$cmd -c <threads> --mem-per-cpu <mem> $post_cmd -o <subvol> -t <threads>"
info "================================================================================"
info ""
pids=()
for i in `eval echo {1..${#shark_subvolumes[*]}}`
do
	let "i = i - 1"
	s=${shark_subvolumes[i]}
	t=${cpus_per_task[i]}
	m=${mem_per_task[i]}
	info "Spawning shark run for subvolume $s with $t threads and $m MB of memory"
	$cmd -c $t --mem-per-cpu $(($m/$t)) $post_cmd -o "execution.simulation_batches=$s" -t $t &> "shark_subvol_${s}.log" &
	pids+=($!)
done

info "Waiting for all instances to finish"
all_good=1
for pid in ${pids[*]}
do
	wait $pid
	if [ $? -ne 0 ]
	then
		all_good=0
	fi
done

if [ $all_good = 0 ]
then
	error "Some (or all) of the shark instances exited with an error"
	error "Check the individual output files for details"
	exit 1
fi
info "All shark instances exited cleanly! :)"

# User requested a plot
if [ -n "${shark_plot}" ]
then

	# For the time being we are assuming this script
	# is alongside the rest of the shark sources
	export MPLBACKEND=agg
	"${shark_python_exec}" "$SHARK_HPC_DIR/../standard_plots/all.py" \
	    -c "${config_file}" -v "${shark_subvolumes[*]}" \
	    -O "${shark_obsdata_dir}" 199 &> shark-plots.log
	if [ $? -ne 0 ]
	then
		warning "An error occurred while producing the plots, please check the shark-plots.log file for details"
	else
		# Find where the plots were produced and copy them
		# to a local plots/ folder for easy access
		info "shark plots successfully produced"
		plots_dir=`"${shark_python_exec}" "$SHARK_HPC_DIR/../standard_plots/common.py" "${config_file}"`
		mkdir plots
		cp ${plots_dir}/* plots
		info "shark plots successfully copied into plots/"
	fi
fi

info "Job done, bye-bye!"
