#!/bin/bash -l
#
# Script to submit shark for execution under different queueing systems
#
# ICRAR - International Centre for Radio Astronomy Research
# (c) UWA - The University of Western Australia, 2018
# Copyright by UWA (in the framework of the ICRAR)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#

info() {
	echo "shark-submit: $1"
}

error() {
	echo "shark-submit: ERROR: $1" 1>&2
}

warning() {
	echo "shark-submit: WARNING: $1" 1>&2
}

get_absolute_path() {
	# Follow symbolic links
	p="$1"
	while [ -h "$p" ]
	do
		p=`readlink -f "$p"`
	done

	# Go to the parent directory and echo $PWD,
	# it will yield an absolute route
	dirname="`dirname $p`"
	basename="`basename $p`"
	cd $dirname
	echo "$PWD/$basename"
	cd $OLDPWD
}

to_bytes() {
	x="$1"
	if [[ "$x" =~ ^([0-9]+)([kKmMgGtT]?) ]]
	then
		amount=${BASH_REMATCH[1]}
		unit=${BASH_REMATCH[2]^*}
	else
		error "unknown memory quantity: $x" && exit 1
	fi

	if [ $unit = K ]
	then
		amount=$(($amount * 1024))
	elif [ $unit = M ]
	then
		amount=$(($amount * 1024 * 1024))
	elif [ $unit = G ]
	then
		amount=$(($amount * 1024 * 1024 * 1024))
	else
		amount=$(($amount * 1024 * 1024 * 1024 * 1024))
	fi

	echo "$amount"
}

print_usage() {
	echo
	echo "$0: Submits shark for execution in a queueing system like SLURM or PBS/Torque"
	echo
	echo "Usage: $0 [-h] [-?] [-d] [-O output_dir] [-Q queue] [-a account] [-w walltime]"
	echo "       [-n job-name] [-M modules] [-M mem] [-N num-nodes] [-v | -q]"
	echo "       [-S shark_binary] [-V subvolumes] [-o opt1=val1 [-o opt2=val2...]]"
	echo "       [-p] [-D obsdata_dir] config_file"
	echo
	echo "This program calculates what is the best way to submit a series of jobs to"
	echo "execute shark over a number of subvolumes, and performs such submission. The"
	echo "resources needed by the submission depend on: a) the number of subvolumes to"
	echo "process (-V option), and b) the memory required by each shark instance"
	echo "(-m option). An additional -N option allows users to manually specify a minimum"
	echo "number of nodes to be requested."
	echo
	echo "General options:"
	echo
	echo " -h, -?          Show this help"
	echo
	echo " -d              Dry-run (i.e., don't actually submit shark)"
	echo
	echo
	echo "Queueing options"
	echo
	echo " -O output_dir   Directory where shark output will be written into. Defaults to"
	echo "                 a rolling shark_run_<xxxx> name. The SHARK_OUTPUT_DIR_BASE"
	echo "                 variable, if present, indicates where these directories should"
	echo "                 be created; otherwise they are created in the current working"
	echo "                 directory. If -W is given, the SHARK_OUTPUT_DIR_BASE variable"
	echo "                 is not taken into account"
	echo
	echo " -Q queue        The queue (or partition, in some queueing system parlance) to"
	echo "                 submit this job to"
	echo
	echo " -a account      The account to which this submission should be billed to"
	echo
	echo " -w walltime     The walltime to apply to this submission. Defaults to 1 [h]"
	echo
	echo " -n job-name     Job name for this submission"
	echo
	echo " -M modules      Colon-separted list of modules to load before running shark."
	echo "                 Defaults to the value of the SHARK_RUNTIME_MODULES environment"
	echo "                 variable, if set."
	echo
	echo " -m mem          Amount of memory needed by each shark instance. It is used to"
	echo "                 calculate the number of nodes required given a number of tasks."
	echo "                 If unspecified, the -N option can be used to manually specify a"
	echo "                 number of nodes"
	echo
	echo " -N num-nodes    Number of nodes to request. If unspecified it is automatically"
	echo "                 calculated based on the number of subvolumes (-V option)"
	echo
	echo
	echo "SHArk-specific options"
	echo
	echo " -v              Run shark in verbose mode"
	echo
	echo " -q              Run shark in quiet mode"
	echo
	echo " -S shark-binary The shark binary to run. Defaults to standard PATH lookup"
	echo
	echo " -V subvolumes   Space-separated list of subvolumes to process. Can contain"
	echo "                 ranges like 1-10. Defaults to whatever is present in the"
	echo "                 configuration file"
	echo
	echo " -o opt=val ...  Extra options to pass down to shark. Options given this way"
	echo "                 override those given in the configuration file. This parameter"
	echo "                 can be given more than one time to pass down multiple options"
	echo
	echo " -p              After a *successful* run, produce all the standard plots with"
	echo "                 the generated outputs from shark, and copy them to this job's"
	echo "                 output directory. The default is to not produce plots"
	echo
	echo " -D              The directory where observational data can be found. Defaults"
	echo "                 to the value of the SHARK_OBSDATA_DIR environment variable, if"
	echo "                 set. A value is required if -p is given"
	echo
	echo " config_file:    The reference configuration file to use for this shark execution"
	echo
}

submit_slurm() {

	# Each SHArk instance uses one CPU
	cmd="sbatch --ntasks $n_svols"
	cmd="$cmd -o shark-run.log"

	# Queueing accountability
	if [ ! -z "$account" ]
	then
		cmd="$cmd -A $account"
	fi

	if [ ! -z "$queue" ]
	then
		cmd="$cmd -p $queue"
	fi

	if [ ! -z "$walltime" ]
	then
		cmd="$cmd --time $walltime"
	fi

	if [ ! -z "$job_name" ]
	then
		cmd="$cmd --job-name $job_name"
	fi

	# Resource limits
	if [ ! -z "$num_nodes" ]
	then
		cmd="$cmd -N $num_nodes"
	fi

	if [ -n "$mem_per_task" ]
	then
		cmd="$cmd --mem-per-cpu $(($mem_per_task / 1024 / 1024))M"
	fi

	cmd="$cmd -D \"$shark_output_directory\""
	cmd="$cmd shark-run -v $shark_verbosity"

	# shark-run command-line options
	if [ ! -z "$modules" ]
	then
		cmd="$cmd -m $modules"
	fi

	if [ ! -z "$shark_binary" ]
	then
		cmd="$cmd -S $shark_binary"
	fi

	# Extra shark options given to shark-submit
	for o in ${shark_options[*]}
	do
		cmd="$cmd -o \"$o\""
	done

	# Produce standard plots?
	if [ -n "${shark_plot}" ]
	then
		cmd="$cmd -p -D \"${shark_obsdata_dir}\""
	fi

	cmd="$cmd -V \"$shark_subvolumes\" $config_file"

	if [ "$dry_run" = "1" ]
	then
		info "SLURM shark job submission command: $cmd"
		info ""
		info "THIS WAS NOT SUBMITTED, since this is a dry run"
		info "If you really want to submit, remove the -d option from the command line"
		info ""
	else
		info "Submitting shark job with command: $cmd"

		# Go, go, go!
		export SHARK_HPC_DIR="$shark_hpc_dir"
		eval $cmd
		if [ $? -ne 0 ]
		then
			error "Error when submitting job to the queue"
			exit 1
		fi
	fi
}

# Default option values
# These are global variables, so we don't need to pass them around all the time
shark_hpc_dir=$(dirname $(get_absolute_path "$0"))
dry_run=
verbose=
quiet=
shark_output_directory=
queue=
account=
job_name=
walltime="1:00:00"
modules=${SHARK_RUNTIME_MODULES}
mem_per_task=
num_nodes=
shark_verbosity=3
shark_binary=
shark_subvolumes=
shark_options=()
shark_plot=
shark_obsdata_dir=${SHARK_OBSDATA_DIR}

# Parse command line options
while getopts "h?dO:Q:a:w:n:M:m:N:vqS:V:o:pD:" opt
do
	case "$opt" in
		[h?])
			print_usage
			exit 0
			;;
		d)
			dry_run=1
			;;
		v)
			if [ ! -z "$quiet" ]
			then
				error "-v and -q cannot be specified together"
				print_usage 1>&2
				exit 1
			fi
			verbose=1
			shark_verbosity=4
			;;
		q)
			if [ ! -z "$verbose" ]
			then
				error "-v and -q cannot be specified together"
				print_usage 1>&2
				exit 1
			fi
			quiet=1
			shark_verbosity=2
			;;
		S)
			shark_binary="$OPTARG"
			;;
		V)
			shark_subvolumes="$OPTARG"
			;;
		o)
			shark_options+=("$OPTARG")
			;;
		p)
			shark_plot=yes
			;;
		D)
			shark_obsdata_dir="${OPTARG}"
			;;
		O)
			shark_output_directory="$OPTARG"
			;;
		Q)
			queue="$OPTARG"
			;;
		a)
			account="$OPTARG"
			;;
		w)
			walltime="$OPTARG"
			;;
		n)
			job_name="$OPTARG"
			;;
		M)
			modules="$OPTARG"
			;;
		m)
			mem_per_task=`to_bytes "$OPTARG"`
			if [ $? -ne 0 ]
			then
				exit 1
			fi
			;;
		N)
			num_nodes="$OPTARG"
			;;
		*)
			print_usage 1>&2
			exit 1
			;;
	esac
done

# Positional argument is the configuration file name
if [ $(($# - $OPTIND)) -lt 0 ]
then
	error "Missing config_file option"
	print_usage 1>&2
	exit 1
fi
config_file=${@:$OPTIND:1}

# If plotting is requested, an observation data directory must be specified
if [ -n "${shark_plot}" ]
then
	if [ -z "${shark_obsdata_dir}" ]
	then
		error "No observations data directory specified."
		error
		error "One can be specified either using -D or with the"
		error "SHARK_OBSDATA_DIR environment variable"
		exit 1
	fi

	if [ ! -d "${shark_obsdata_dir}" ]
	then
		error "Observations data directory"
		error
		error "${shark_obsdata_dir}"
		error
		error "does not exist or is not a directory."
		error "Make sure you are pointing to the correct directory,"
		error "or do *not* request plots via -p"
		exit 1
	fi
fi

#
# If a shark binary is indicated, make sure we get an absolute path
# to it to avoid errors with relative paths later during the execution
# of shark-run, which is probably running somewhere else than this
# directory
#
if [ -n "$shark_binary" ]
then
	if [ ! -e "$shark_binary" ]
	then
		error "$shark_binary does not exist, check the -S option"
		exit 1
	fi
	shark_binary=`get_absolute_path "$shark_binary"`
fi


# Check which queueing system we are going to use from now on
queue_system=
if [ ! -z "$(command -v sbatch 2> /dev/null)" ]
then
	queue_system="SLURM"
elif [ ! -z "$(command -v qsub 2> /dev/null)" ]
then
	queue_system="PBS/Torque"
else
	error ""
	error "THIS IS NOT MEANT TO HAPPEN"
	error ""
	error "You seem to be running this script in an environment that doesn't have any"
	error "queueing system present (like PBS/Torque or SLURM), which probably means one"
	error "of two things:"
	error ""
	error " 1) You are not running this in an HPC facility"
	error " 2) You are running this in an HPC facility, but this script doesn't support"
	error "    your queueing system (yet)."
	error ""
	error "In the case of 1), you probably want to run shark manually. To do that, you can"
	error "run the \"shark\" binary directly. Use \"shark --help\" for details on how to"
	error "run shark manually."
	error ""
	error "In the (very unfortunate) case of 2), please contact the shark authors with the"
	error "details of your queueing system so they can add the corresponding support to"
	error "this script in future versions of shark."
	error ""
	exit 1
fi

# Make sure the configuration file exists
if [ ! -f ${config_file} ]
then
	error "File ${config_file} is not an existing (or accessible) file"
	exit 1
fi

# Check which subvolumes we are meant to run shark on
# This will determine the number of nodes we request
# at the end of the day
if [ -z "$shark_subvolumes" ]
then
	# Default to whatever is written into the configuration file
	shark_subvolumes="`egrep '^simulation_batches' "$config_file" | sed -e 's/^simulation_batches\s*=\s*\([^#]\+\).*/\1/'`"

	# If there's nothing in the configuration file, then... is it really one?
	if [ -z "$shark_subvolumes" ]
	then
		error ""
		error "No subvolumes were given via the -V option, but none could found either in"
		error "${config_file}. Is ${config_file} really a shark configuration file?"
		error ""
		error "If it is, and you don't want to pass down the -V option every time, then"
		error "you want to put have a \"simulation_batches\" option under the \"execution\""
		error "group set to the list of subvolumes that shark should process."
		error ""
		error "See the output of -h for more information on how to use this script to run"
		error "shark against many subvolumes."
		error ""
		exit 1
	fi
fi

# Convert subvolumes specification (which may contain space- and
# hypen-separated values) into a proper list of values
svols=""
for s in $shark_subvolumes
do
	if [[ "$s" == *"-"* ]]
	then
		first=${s%%-*}
		second=${s##*-}
		for i in `eval echo {${first}..${second}}`
		do
			svols="$svols $i"
		done
	else
		svols="$svols $s"
	fi
done
shark_subvolumes="$svols"
svols=($svols)
n_svols=${#svols[@]}
info "Will submit shark to work on $n_svols subvolumes: $shark_subvolumes"

# Make sure we have a proper working directory
if [ ! -z "$shark_output_directory" ]
then
	mkdir -p "$shark_output_directory"
	if [ ! -d "$shark_output_directory" ]
	then
		error "Couldn't create shark output directory at $shark_output_directory"
		exit 1
	fi
else
	basedir=${SHARK_OUTPUT_DIR_BASE:-.}
	i=0
	for i in `seq -w 1 9999`
	do
		shark_output_directory="$basedir/shark_run_$i"
		test ! -d "$shark_output_directory" && mkdir -p "$shark_output_directory" &> /dev/null && break
	done
fi
info "Will run shark-run under $shark_output_directory"

# Copy the configuration file over to the working directory
config_file_bname=`basename $config_file`
cp "$config_file" "$shark_output_directory"
config_file="$config_file_bname"
info "Configuration file copied to $shark_output_directory/$config_file"

# Go, go, go!
info "Submitting shark to $queue_system"
if [ $queue_system = SLURM ]
then
	submit_slurm
else
	error "PBS/Torque still not supported"
	exit 1
fi

info "Submissiong successful. Thanks for using our shark-submit script, come back soon :-)"
