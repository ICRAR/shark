#!/bin/bash -l
#
# Script to submit shark for execution under different queueing systems
#
# ICRAR - International Centre for Radio Astronomy Research
# (c) UWA - The University of Western Australia, 2018
# Copyright by UWA (in the framework of the ICRAR)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#

info() {
	echo "shark-submit: $1"
}

error() {
	echo "shark-submit: ERROR: $1" 1>&2
}

warning() {
	echo "shark-submit: WARNING: $1" 1>&2
}

get_absolute_path() {
	# Follow symbolic links
	p="$1"
	while [ -h "$p" ]
	do
		p=`readlink -f "$p"`
	done

	# Go to the parent directory and echo $PWD,
	# it will yield an absolute route
	dirname="`dirname $p`"
	basename="`basename $p`"
	cd $dirname
	echo "$PWD/$basename"
	cd $OLDPWD
}

check_file_exists() {
	if [ ! -f "$1" ]
	then
		error "File $1 is not an existing (or accessible) file$2"
		exit 1
	fi
}

to_bytes() {
	x="$1"
	if [[ "$x" =~ ^([0-9]+)([kKmMgGtT]?) ]]
	then
		amount=${BASH_REMATCH[1]}
		unit=${BASH_REMATCH[2]^*}
	else
		error "unknown memory quantity: $x" && exit 1
	fi

	if [ $unit = K ]
	then
		amount=$(($amount * 1024))
	elif [ $unit = M ]
	then
		amount=$(($amount * 1024 * 1024))
	elif [ $unit = G ]
	then
		amount=$(($amount * 1024 * 1024 * 1024))
	else
		amount=$(($amount * 1024 * 1024 * 1024 * 1024))
	fi

	echo "$amount"
}

print_usage_summary() {
	echo
	echo "usage: $0 [options...] config_file"
	echo
	echo "For more comprehensive help use -h or -?"
}

print_usage() {
	echo
	echo "$0: Submits shark for execution in a queueing system like SLURM or PBS/Torque"
	echo
	echo "Usage: $0 [-h] [-?] [-d] [-O output_dir] [-Q queue] [-a account] [-w walltime]"
	echo "       [-n job-name] [-M modules] [-m mem] [-c cpus] [-N num-nodes] [-v | -q]"
	echo "       [-S shark_binary] [-V subvolumes] [-o opt1=val1 [-o opt2=val2...]]"
	echo "       [-E params-file] [-p] [-P python-exec] config_file"
	echo
	echo "This program calculates what is the best way to submit a series of jobs to"
	echo "execute shark over a number of subvolumes, and performs such submission. The"
	echo "resources needed by the submission depend on: a) the number of subvolumes to"
	echo "process (-V option) or the number of parameters in the paramter file (-E option,"
	echo "and b) the memory required by each shark instance (-m option). An additional"
	echo "option allows users to manually specify a minimum number of nodes to be"
	echo "requested (-N)."
	echo
	echo "General options"
	echo "---------------"
	echo
	echo " -h, -?          Show this help"
	echo
	echo " -d              Dry-run (i.e., don't actually submit shark)"
	echo
	echo
	echo "Queueing options"
	echo "----------------"
	echo
	echo " -O output_dir   Directory where shark output will be written into. Defaults to"
	echo "                 a rolling shark_run_<xxxx> name. The SHARK_OUTPUT_DIR_BASE"
	echo "                 variable, if present, indicates where these directories should"
	echo "                 be created; otherwise they are created in the current working"
	echo "                 directory. If -W is given, the SHARK_OUTPUT_DIR_BASE variable"
	echo "                 is not taken into account"
	echo
	echo " -Q queue        The queue (or partition, in some queueing system parlance) to"
	echo "                 submit this job to"
	echo
	echo " -a account      The account to which this submission should be billed to"
	echo
	echo " -w walltime     The walltime to apply to this submission. Defaults to 1 [h]"
	echo
	echo " -n job-name     Job name for this submission"
	echo
	echo " -M modules      Colon-separted list of modules to load before running shark."
	echo "                 Defaults to the value of the SHARK_RUNTIME_MODULES environment"
	echo "                 variable, if set."
	echo
	echo " -m mem          Amount of memory needed by each shark instance. It is used to"
	echo "                 calculate the number of nodes required given a number of tasks."
	echo "                 If unspecified, the -N option can be used to manually specify a"
	echo "                 number of nodes"
	echo
	echo " -c cpus         Number of CPUs to allocate to each shark instance."
	echo
	echo " -N num-nodes    Number of nodes to request. If unspecified it is automatically"
	echo "                 calculated based on the number of subvolumes (-V option)"
	echo
	echo
	echo "Plotting options"
	echo "----------------"
	echo
	echo " -p              After a *successful* run, produce all the standard plots with"
	echo "                 the generated outputs from shark, and copy them to this job's"
	echo "                 output directory. The default is to not produce plots"
	echo
	echo " -P python-exec  Use the given python executable to run the plot scripts. Useful"
	echo "                 when using a Python virtual environment."
	echo
	echo
	echo "shark options"
	echo "-------------"
	echo
	echo " -v              Run shark in verbose mode"
	echo
	echo " -q              Run shark in quiet mode"
	echo
	echo " -S shark-binary The shark binary to run. Defaults to standard PATH lookup"
	echo
	echo " -V subvolumes   Space-separated list of subvolumes to process. Can contain"
	echo "                 ranges like 1-10. Defaults to whatever is present in the"
	echo "                 configuration file. One independent shark instance will be"
	echo "                 spawned for each subvolume in parallel"
	echo
	echo " -E params-file  File specifying sets of shark options, one set per line. When"
	echo "                 this file is given, one shark instance will be spawned for each"
	echo "                 parameter set (instead of one shark instance per subvolume) in"
	echo "                 parallel, and each instance will use all subvolumes indicated"
	echo "                 by the -V option"
	echo
	echo " -o opt=val ...  Extra options to pass down to shark. Options given this way"
	echo "                 override those given in the configuration file. This parameter"
	echo "                 can be given more than one time to pass down multiple options"
	echo
	echo " config_file:    The reference configuration file to use for this shark execution"
	echo
	echo
	echo "Environment variables"
	echo "====================="
	echo
	echo " * SHARK_OUTPUT_DIR_BASE  Default prefix where shark_run_<xxx> dirs are created"
	echo " * SHARK_ACCOUNT          Default value for the -a option"
	echo " * SHARK_QUEUE            Default value for the -Q option"
	echo " * SHARK_RUNTIME_MODULES  Default value for the -M option"
	echo
	echo
	echo "Examples"
	echo "========"
	echo
	echo "$> shark-submit -Q debug -S ../build/shark -V 0-9 myconfig.cfg"
	echo
	echo "   Creates a job submission that will submit the execution of 10 shark instances"
	echo "   for subvolumes from 0 to 9 using the common configuration file 'myconfig.cfg'"
	echo "   and the shark binary '../build/shark'. The submission is performed to the "
	echo "  'debug' queue"
	echo
	echo "$> shark-submit -V 0-9 -E params-file.txt myconfig.cfg"
	echo
	echo "   Creates a job submission that will submit the execution of N shark instances,"
	echo "   one for each line in <params-file.txt>. Each instance will process subvolumes"
	echo "   from 0 to 9 using the common configuration file 'myconfig.cfg' and the"
	echo "   corresponding options contained in the params-file.txt file"
	echo
	echo "$> shark-submit -m 7g -M gsl/2.3:hdf5/1.10.2:gcc/6.3 -p -N 10 -V '0-32 34-63'"
	echo "   -Q debug myconfig.cfg"
	echo
	echo "   Like above, but executing for subvolumes from 0 to 63 (excluding 33), each"
	echo "   instance needing 7 [GB] of memory, requesting 10 computing nodes, loading "
	echo "   the gsl/2.3, hdf5/1.10.2 and gcc/6.3 modules before launching shark, and"
	echo "   producing all standard plots"
	echo
	echo "$> shark-submit -Q debug -m 7g -p -N 10 -V '0-32 34-63' myconfig.cfg"
	echo
	echo "   Like above, but assuming that SHARK_RUNTIME_MODULES is already set, in which"
	echo "   case its value does not need to be specified"
	echo
}

submit_slurm() {

	# Each SHArk instance will be ran as a task
	cmd="sbatch --export ALL --ntasks $n_tasks"
	cmd="$cmd -o shark-run.log"

	# Get the ID of the new job
	cmd="$cmd --parsable"

	# Queueing accountability
	if [ ! -z "$account" ]
	then
		cmd="$cmd -A $account"
	fi

	if [ ! -z "$queue" ]
	then
		cmd="$cmd -p $queue"
	fi

	if [ ! -z "$walltime" ]
	then
		cmd="$cmd --time $walltime"
	fi

	if [ ! -z "$job_name" ]
	then
		cmd="$cmd --job-name $job_name"
	fi

	# Resource limits
	if [ ! -z "$num_nodes" ]
	then
		cmd="$cmd -N $num_nodes"
	fi

	if [ -n "$mem_per_task" ]
	then
		# Scale memory-per-task to memory-per-CPU
		mem=$(($mem_per_task / 1024 / 1024))
		if [ -n "$cpus_per_task" ]; then
			mem=$((mem / $cpus_per_task))
		fi
		cmd="$cmd --mem-per-cpu ${mem}M"
	fi

	if [ -n "$cpus_per_task" ]
	then
		cmd="$cmd --cpus-per-task $cpus_per_task"
	fi

	cmd="$cmd -D \"$shark_output_directory\""
	cmd="$cmd shark-run -v $shark_verbosity"

	# shark-run command-line options
	if [ ! -z "$modules" ]
	then
		cmd="$cmd -m $modules"
	fi

	if [ ! -z "$shark_binary" ]
	then
		cmd="$cmd -S $shark_binary"
	fi

	# Extra shark options given to shark-submit
	for o in ${shark_options[*]}
	do
		cmd="$cmd -o \"$o\""
	done

	# Produce standard plots?
	if [ -n "${shark_plot}" ]
	then
		cmd="$cmd -p -P \"${shark_python_exec}\""
	fi

	cmd="$cmd -E \"$shark_params_file\""
	cmd="$cmd -V \"$shark_subvolumes\" $config_file"

	if [ "$dry_run" = "1" ]
	then
		info "SLURM shark job submission command: $cmd"
		info ""
		info "THIS WAS NOT SUBMITTED, since this is a dry run"
		info "If you really want to submit, remove the -d option from the command line"
		info ""
	else
		info "Submitting shark job with command: $cmd"

		# Go, go, go!
		export SHARK_HPC_DIR="$shark_hpc_dir"
		job_id=`eval $cmd`
		if [ $? -ne 0 ]
		then
			error "Error when submitting job to the queue"
			exit 1
		else
			info "New job submitted with ID $job_id"
			echo "$job_id" > "${shark_output_directory}"/jobid
		fi
	fi
}

# Default option values
# These are global variables, so we don't need to pass them around all the time
shark_hpc_dir=$(dirname $(get_absolute_path "$0"))
dry_run=
verbose=
quiet=
shark_output_directory=
queue=${SHARK_QUEUE}
account=${SHARK_ACCOUNT}
job_name=
walltime="1:00:00"
modules=${SHARK_RUNTIME_MODULES}
mem_per_task=
shark_params_file=
cpus_per_task=
num_nodes=
shark_verbosity=3
shark_binary=
shark_subvolumes=
shark_options=()
shark_plot=
shark_python_exec=python

# Parse command line options
while getopts "h?dO:Q:a:w:n:M:m:c:N:E:vqS:V:o:pP:" opt
do
	case "$opt" in
		[h?])
			print_usage
			exit 0
			;;
		d)
			dry_run=1
			;;
		v)
			if [ ! -z "$quiet" ]
			then
				error "-v and -q cannot be specified together"
				print_usage_summary 1>&2
				exit 1
			fi
			verbose=1
			shark_verbosity=4
			;;
		q)
			if [ ! -z "$verbose" ]
			then
				error "-v and -q cannot be specified together"
				print_usage_summary 1>&2
				exit 1
			fi
			quiet=1
			shark_verbosity=2
			;;
		S)
			shark_binary="$OPTARG"
			check_file_exists "${shark_binary}" ", please check the -S option"
			;;
		V)
			shark_subvolumes="$OPTARG"
			;;
		o)
			shark_options+=("$OPTARG")
			;;
		E)
			shark_params_file="$OPTARG"
			check_file_exists "${shark_params_file}" ", please check the -E option"
			;;
		p)
			shark_plot=yes
			;;
		P)
			shark_python_exec="${OPTARG}"
			;;
		O)
			shark_output_directory="$OPTARG"
			;;
		Q)
			queue="$OPTARG"
			;;
		a)
			account="$OPTARG"
			;;
		w)
			walltime="$OPTARG"
			;;
		n)
			job_name="$OPTARG"
			;;
		M)
			modules="$OPTARG"
			;;
		m)
			mem_per_task=`to_bytes "$OPTARG"`
			if [ $? -ne 0 ]
			then
				exit 1
			fi
			;;
		c)
			cpus_per_task="$OPTARG"
			;;
		N)
			num_nodes="$OPTARG"
			;;
		*)
			print_usage_summary 1>&2
			exit 1
			;;
	esac
done

# Positional argument is the configuration file name
if [ $(($# - $OPTIND)) -lt 0 ]
then
	error "Missing config_file option"
	print_usage_summary 1>&2
	exit 1
fi
config_file=${@:$OPTIND:1}
check_file_exists "${config_file}"

#
# Check that everything is in place if plotting is requested
#
if [ -n "${shark_plot}" ]
then
	# The python binary must be there
	if [ "${shark_python_exec}" != "python" ]
	then
		check_file_exists "${shark_python_exec}" ", please check the -P option"
		shark_python_exec=`get_absolute_path "${shark_python_exec}"`
	fi
fi

#
# If a shark binary is indicated, make sure we get an absolute path
# to it to avoid errors with relative paths later during the execution
# of shark-run, which is probably running somewhere else than this
# directory
#
if [ -n "$shark_binary" ]
then
	check_file_exists "${shark_binary}" ", please check the -S option"
	shark_binary=`get_absolute_path "$shark_binary"`
fi


# Check which queueing system we are going to use from now on
queue_system=
if [ ! -z "$(command -v sbatch 2> /dev/null)" ]
then
	queue_system="SLURM"
elif [ ! -z "$(command -v qsub 2> /dev/null)" ]
then
	queue_system="PBS/Torque"
else
	error ""
	error "THIS IS NOT MEANT TO HAPPEN"
	error ""
	error "You seem to be running this script in an environment that doesn't have any"
	error "queueing system present (like PBS/Torque or SLURM), which probably means one"
	error "of two things:"
	error ""
	error " 1) You are not running this in an HPC facility"
	error " 2) You are running this in an HPC facility, but this script doesn't support"
	error "    your queueing system (yet)."
	error ""
	error "In the case of 1), you probably want to run shark manually. To do that, you can"
	error "run the \"shark\" binary directly. Use \"shark --help\" for details on how to"
	error "run shark manually."
	error ""
	error "In the (very unfortunate) case of 2), please contact the shark authors with the"
	error "details of your queueing system so they can add the corresponding support to"
	error "this script in future versions of shark."
	error ""
	exit 1
fi

# Check which subvolumes we are meant to run shark on
# This will determine the number of nodes we request
# at the end of the day
if [ -z "$shark_subvolumes" ]
then
	# Default to whatever is written into the configuration file
	shark_subvolumes="`egrep '^simulation_batches' "$config_file" | sed -e 's/^simulation_batches\s*=\s*\([^#]\+\).*/\1/'`"

	# If there's nothing in the configuration file, then... is it really one?
	if [ -z "$shark_subvolumes" ]
	then
		error ""
		error "No subvolumes were given via the -V option, but none could found either in"
		error "${config_file}. Is ${config_file} really a shark configuration file?"
		error ""
		error "If it is, and you don't want to pass down the -V option every time, then"
		error "you want to put have a \"simulation_batches\" option under the \"execution\""
		error "group set to the list of subvolumes that shark should process."
		error ""
		error "See the output of -h for more information on how to use this script to run"
		error "shark against many subvolumes."
		error ""
		exit 1
	fi
fi

# Convert subvolumes specification (which may contain space- and
# hypen-separated values) into a proper list of values
svols=""
for s in $shark_subvolumes
do
	if [[ "$s" == *"-"* ]]
	then
		first=${s%%-*}
		second=${s##*-}
		for i in `eval echo {${first}..${second}}`
		do
			svols="$svols $i"
		done
	else
		svols="$svols $s"
	fi
done
shark_subvolumes="$svols"
svols=($svols)
n_svols=${#svols[@]}
info "Will submit shark to work on $n_svols subvolumes: $shark_subvolumes"

if [ -n "$shark_params_file" ]
then
	n_tasks=$(wc -l < $shark_params_file)
else
	n_tasks=$n_svols
fi

info "Will submit shark to work on $n_tasks tasks"


# Make sure we have a proper working directory
if [ ! -z "$shark_output_directory" ]
then
	mkdir -p "$shark_output_directory"
	if [ ! -d "$shark_output_directory" ]
	then
		error "Couldn't create shark output directory at $shark_output_directory"
		exit 1
	fi
else
	basedir=${SHARK_OUTPUT_DIR_BASE:-.}
	i=0
	for i in `seq -w 1 9999`
	do
		shark_output_directory="$basedir/shark_run_$i"
		test ! -d "$shark_output_directory" && mkdir -p "$shark_output_directory" &> /dev/null && break
	done
fi
info "Will run shark-run under $shark_output_directory"

# Copy the configuration and parameter files over to the working directory
config_file_bname=`basename $config_file`
cp "$config_file" "$shark_output_directory"
config_file="$config_file_bname"
info "Configuration file copied to $shark_output_directory/$config_file"

if [ -n "$shark_params_file" ]
then
	bname=`basename $shark_params_file`
	cp "$shark_params_file" "$shark_output_directory"
	shark_params_file="$bname"
	info "Parameters file copied to $shark_output_directory/$shark_params_file"
fi

# Go, go, go!
info "Submitting shark to $queue_system"
if [ $queue_system = SLURM ]
then
	submit_slurm
else
	error "PBS/Torque still not supported"
	exit 1
fi

info "Submission successful. Thanks for using our shark-submit script, come back soon :-)"
